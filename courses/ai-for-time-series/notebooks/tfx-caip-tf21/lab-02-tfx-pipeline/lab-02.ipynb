{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Set `PATH` to include the directory containing TFX CLI.\n",
    "PATH=%env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\"\n",
    "!python -c \"import kfp; print('KFP version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous training with TFX and Cloud AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab walks you through a TFX pipeline that uses **Cloud Dataflow** and **Cloud AI Platform Training** as execution runtimes. The pipeline implements a typical TFX workflow as depicted on the below diagram:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the pipeline design\n",
    "The pipeline source code can be found in the `pipeline` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `config.py` module configures the default values for the environment specific settings and the default values for the pipeline runtime parameters. \n",
    "The default values can be overwritten at compile time by providing the updated values in a set of environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline.py` module contains the TFX DSL defining the workflow implemented by the pipeline.\n",
    "\n",
    "The `preprocessing.py` module implements the data preprocessing logic  the `Transform` component.\n",
    "\n",
    "The `model.py` module implements the training logic for the   `Train` component.\n",
    "\n",
    "The `runner.py` module configures and executes `KubeflowDagRunner`. At compile time, the `KubeflowDagRunner.run()` method conversts the TFX DSL into the pipeline package in the [argo](https://argoproj.github.io/argo/) format.\n",
    "\n",
    "The `features.py` module contains feature definitions common across `preprocessing.py` and `model.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and deploying the pipeline\n",
    "\n",
    "You will use TFX CLI to compile and deploy the pipeline. As explained in the previous section, the environment specific settings can be provided through a set of environment variables and embedded into the pipeline package at compile time.\n",
    "\n",
    "### Configure environment settings\n",
    "\n",
    "Update  the below constants  with the settings reflecting your lab environment. \n",
    "\n",
    "- `GCP_REGION` - the compute region for AI Platform Training and Prediction\n",
    "- `ARTIFACT_STORE` - the GCS bucket created during installation of AI Platform Pipelines. The bucket name starts with the `hostedkfp-default-` prefix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ENDPOINT` - set the `ENDPOINT` constant to the endpoint to your AI Platform Pipelines instance. The endpoint to the AI Platform Pipelines instance can be found on the [AI Platform Pipelines](https://console.cloud.google.com/ai-platform/pipelines/clusters) page in the Google Cloud Console.\n",
    "\n",
    "1. Open the *SETTINGS* for your instance\n",
    "2. Use the value of the `host` variable in the *Connect to this Kubeflow Pipelines instance from a Python client via Kubeflow Pipelines SKD* section of the *SETTINGS* window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP_REGION = 'us-central1'\n",
    "ENDPOINT = '490ab949a23d5f6d-dot-us-central2.pipelines.googleusercontent.com'\n",
    "ARTIFACT_STORE_URI = 'gs://hostedkfp-default-36un4wco1q'\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the pipeline\n",
    "\n",
    "You can build and upload the pipeline to the AI Platform Pipelines instance in one step, using the `tfx pipeline create` command. The `tfx pipeline create` goes through the following steps:\n",
    "- (Optional) Builds the custom image to that provides a runtime environment for TFX components, \n",
    "- Compiles the pipeline DSL into a pipeline package \n",
    "- Uploads the pipeline package to the instance.\n",
    "\n",
    "As you debug the pipeline DSL, you may prefer to first use the `tfx pipeline compile` command, which only executes the compilation step. After the DSL compiles successfully you can use `tfx pipeline create` to go through all steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the pipeline's compile time settings\n",
    "\n",
    "The pipeline can run using a security context of the GKE default node pool's service account or the service account defined in the `user-gcp-sa` secret of the Kubernetes namespace hosting Kubeflow Pipelines. If you want to use the `user-gcp-sa` service account you change the value of `USE_KFP_SA` to `True`.\n",
    "\n",
    "Note that the default AI Platform Pipelines configuration does not define the `user-gcp-sa` secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'tfx_covertype_continuous_training'\n",
    "MODEL_NAME = 'tfx_covertype_classifier'\n",
    "\n",
    "USE_KFP_SA=False\n",
    "DATA_ROOT_URI = 'gs://workshop-datasets/covertype/small'\n",
    "CUSTOM_TFX_IMAGE = 'gcr.io/{}/{}'.format(PROJECT_ID, PIPELINE_NAME)\n",
    "RUNTIME_VERSION = '2.1'\n",
    "PYTHON_VERSION = '3.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJECT_ID={PROJECT_ID}\n",
    "%env KUBEFLOW_TFX_IMAGE={CUSTOM_TFX_IMAGE}\n",
    "%env ARTIFACT_STORE_URI={ARTIFACT_STORE_URI}\n",
    "%env DATA_ROOT_URI={DATA_ROOT_URI}\n",
    "%env GCP_REGION={GCP_REGION}\n",
    "%env MODEL_NAME={MODEL_NAME}\n",
    "%env PIPELINE_NAME={PIPELINE_NAME}\n",
    "%env RUNTIME_VERSION={RUNTIME_VERSION}\n",
    "%env PYTHON_VERIONS={PYTHON_VERSION}\n",
    "%env USE_KFP_SA={USE_KFP_SA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx pipeline compile --engine kubeflow --pipeline_path runner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the pipeline package to AI Platform Pipelines\n",
    "\n",
    "After the pipeline code compiles without any errors you can use the `tfx pipeline create` command to perform the full build and deploy the pipeline. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx pipeline create  \\\n",
    "--pipeline_path=runner.py \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--build_target_image={CUSTOM_TFX_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to redeploy the pipeline you can first delete the previous version using `tfx pipeline delete` or you can update the pipeline in-place using `tfx pipeline update`.\n",
    "\n",
    "To delete the pipeline:\n",
    "\n",
    "`tfx pipeline delete --pipeline_name {PIPELINE_NAME} --endpoint {ENDPOINT}`\n",
    "\n",
    "To update the pipeline:\n",
    "\n",
    "`tfx pipeline update --pipeline_path runner.py --endpoint {ENDPOINT}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and monitor a pipeline run\n",
    "After the pipeline has been deployed, you can trigger and monitor pipeline runs using TFX CLI or KFP UI.\n",
    "\n",
    "To submit the pipeline run using TFX CLI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx run create --pipeline_name={PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list all active runs of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfx run list --pipeline_name {PIPELINE_NAME} --endpoint {ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the status of a given run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID='[YOUR RUN ID]'\n",
    "\n",
    "!tfx run status --pipeline_name {PIPELINE_NAME} --run_id {RUN_ID} --endpoint {ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
