{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\">\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Running code\n",
        "\n",
        "Code cells can be executed in sequence by pressing Shift-ENTER. Try it now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k5QBNS8zPteE",
        "colab": {}
      },
      "source": [
        "import math\n",
        " # Colaboratory supports Tensorflow 1.x and Tensorflow 2. %tensorflow_version magic is used to switch.\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "colab": {}
      },
      "source": [
        "a=1\n",
        "b=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "colab": {}
      },
      "source": [
        "a+b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UgR1-U1eQKhJ"
      },
      "source": [
        "## Hidden cells\n",
        "Some cells contain code that is necessary but not interesting for the exercise at hand. These cells will typically be collapsed to let you focus at more interesting pieces of code. If you want to see their contents, double-click the cell. Wether you peek inside or not, **you must run the hidden cells for the code inside to be interpreted**. Try it now, the cell is marked **RUN ME**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "pG-s3-a_Ppqv",
        "colab": {}
      },
      "source": [
        "#@title \"Hidden cell with boring code [RUN ME]\"\n",
        "\n",
        "def display_sinusoid():\n",
        "  X = range(180)\n",
        "  Y = [math.sin(x/10.0) for x in X]\n",
        "  plt.plot(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILZmeORzRaJB",
        "colab": {}
      },
      "source": [
        "display_sinusoid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "Did it work ? If not, run the collapsed cell marked **RUN ME** and try again!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## Accelerators\n",
        "\n",
        "Colaboratory offers free GPU and TPU (Tensor Processing Unit) accelerators.\n",
        "\n",
        "You can choose your accelerator in *Runtime > Change runtime type*\n",
        "\n",
        "The cell below is the standard boilerplate code that enables distributed training on GPUs or TPUs in Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TDwroXseS27Z",
        "colab": {}
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "    \n",
        "# Select appropriate distribution strategy for hardware\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.master())  \n",
        "elif len(gpus) > 0:\n",
        "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
        "  print('Running on ', len(gpus), ' GPU(s) ')\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "# How many accelerators do we have ?\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "\n",
        "# To use the selected distribution strategy:\n",
        "# with strategy.scope:\n",
        "#    # --- define your (Keras) model here ---\n",
        "#\n",
        "# For distributed computing, the batch size and learning rate need to be adjusted:\n",
        "# global_batch_size = BATCH_SIZE * strategy.num_replicas_in_sync # num replcas is 8 on a single TPU or N when runing on N GPUs.\n",
        "# learning_rate = LEARNING_RATE * strategy.num_replicas_in_sync"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR9Ug1E79SZK",
        "colab_type": "text"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq9yuTXI9SZK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "author: Martin Gorner<br>\n",
        "twitter: @martin_gorner\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose\n"
      ]
    }
  ]
}