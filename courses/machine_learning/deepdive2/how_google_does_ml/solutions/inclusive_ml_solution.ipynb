{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusive ML - Understanding Bias\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "In this lab, you use a Juypter Notebook to:\n",
    "- Invoke the What-if Tool against a deployed Model\n",
    "- Explore attributes of the dataset\n",
    "- Examine aspects of bias in model results\n",
    "- Evaluate how the What-if Tool provides suggestions to remediate bias\n",
    "\n",
    "---\n",
    "## Introduction \n",
    "\n",
    "This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) inside of a Jupyter notebook.  The What-If Tool, among many other things, allows us to explore the impacts of Fairness in model design and deployment.\n",
    "\n",
    "The notebook invokes a deployed XGBoost classifier model on the [UCI census dataset](https://archive.ics.uci.edu/ml/datasets/census+income) which predicts whether a person earns more than $50K based on their census information.\n",
    "\n",
    "You will then visualize the results of the trained classifier on test data using the What-If Tool.  \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the libraries needed for the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "witwidget==1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep witwidget || pip install witwidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import witwidget\n",
    "from witwidget.notebook.visualization import (\n",
    "    WitWidget, \n",
    "    WitConfigBuilder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, replace `<YOUR PROJEC>` by your GCP project id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"<YOUR PROJEC>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"gs://{project}\".format(project=PROJECT)\n",
    "MODEL = 'xgboost_model'\n",
    "VERSION = 'v1'\n",
    "MODEL_DIR = os.path.join(BUCKET, MODEL)\n",
    "\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['MODEL'] = MODEL\n",
    "os.environ['VERSION'] = VERSION\n",
    "os.environ['MODEL_DIR'] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the notebook environment\n",
    "\n",
    "First you must perform a few environment and project configuration steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These steps may take 8 - 10 minutes, please wait until you see the following response before proceeding:\n",
    "\n",
    "\"__Creating version (this might take a few minutes)......done.__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dherin-sandbox/2fc645062bfd281c454046b0874f5fd79e8b9f7bc601be3196e270ed3fc2cb7a/\n",
      "gs://dherin-sandbox/4e5c2dffdbaae7a20248b858a136de165fe4c22fad881716f61e50415282e220/\n",
      "gs://dherin-sandbox/datasets/\n",
      "gs://dherin-sandbox/taxifare/\n",
      "gs://dherin-sandbox/text2hub/\n",
      "gs://dherin-sandbox/xgboost_model/\n",
      "xgboost_model  v1\n",
      "v1    gs://dherin-sandbox/xgboost_model  READY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Copying gs://cloud-training-demos/mlfairness/model.bst [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 65.2 KiB]                                                \r",
      "/ [1 files][ 65.2 KiB/ 65.2 KiB]                                                \r\n",
      "Operation completed over 1 objects/65.2 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud config set project $PROJECT\n",
    "\n",
    "gsutil ls $BUCKET || gsutil mb $BUCKET\n",
    "gsutil cp gs://cloud-training-demos/mlfairness/model.bst $MODEL_DIR/model.bst\n",
    "\n",
    "gcloud ai-platform models list | grep $MODEL || gcloud ai-platform models create $MODEL\n",
    "\n",
    "gcloud ai-platform versions list --model $MODEL | grep $VERSION ||\n",
    "gcloud ai-platform versions create $VERSION \\\n",
    "  --model=$MODEL \\\n",
    "  --framework='XGBOOST' \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --origin=$MODEL_DIR \\\n",
    "  --python-version=3.5 \\\n",
    "  --project=$PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Finally download the data and arrays needed to use the What-if Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-training-demos/mlfairness/income.pkl...\n",
      "/ [0 files][    0.0 B/  1.6 MiB]                                                \r",
      "/ [1 files][  1.6 MiB/  1.6 MiB]                                                \r\n",
      "Operation completed over 1 objects/1.6 MiB.                                      \n",
      "Copying gs://cloud-training-demos/mlfairness/x_test.npy...\n",
      "/ [0 files][    0.0 B/572.5 KiB]                                                \r",
      "/ [1 files][572.5 KiB/572.5 KiB]                                                \r\n",
      "Operation completed over 1 objects/572.5 KiB.                                    \n",
      "Copying gs://cloud-training-demos/mlfairness/y_test.npy...\n",
      "/ [0 files][    0.0 B/ 63.7 KiB]                                                \r",
      "/ [1 files][ 63.7 KiB/ 63.7 KiB]                                                \r\n",
      "Operation completed over 1 objects/63.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gsutil cp gs://cloud-training-demos/mlfairness/income.pkl .\n",
    "gsutil cp gs://cloud-training-demos/mlfairness/x_test.npy .\n",
    "gsutil cp gs://cloud-training-demos/mlfairness/y_test.npy .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle('income.pkl')\n",
    "x_test = np.load('x_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now take a quick look at the data.  The ML model type used for this analysis is XGBoost.  XGBoost is a machine learning framework that uses decision trees and gradient boosting to build predictive models. It works by ensembling multiple decision trees together based on the score associated with different leaf nodes in a tree. \n",
    "\n",
    "XGBoost requires all values to be numeric so the orginial dataset was modified slightly.  The biggest change made was to assign a numeric value to Sex.  The originial dataset only had the values \"Female\" and \"Male\" for Sex.  The decision was made to assign the value \"1\" to Female and \"2\" to Male. As part of the data prepartion effort the Pandas function \"get_dummies\" was used to convert the remaining domain values into numerical equivalent.  For instance the \"Education\" column was turned into several sub-columns named after the value in the column.  For instance the \"Education_HS-grad\" has a value of \"1\" for when that was the orginial categorical value and a value of \"0\" for other cateogries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital_Gain</th>\n",
       "      <th>Capital_Loss</th>\n",
       "      <th>Hours_per_week</th>\n",
       "      <th>Workclass_ ?</th>\n",
       "      <th>Workclass_ Federal-gov</th>\n",
       "      <th>Workclass_ Local-gov</th>\n",
       "      <th>Workclass_ Never-worked</th>\n",
       "      <th>Workclass_ Private</th>\n",
       "      <th>Workclass_ Self-emp-inc</th>\n",
       "      <th>Workclass_ Self-emp-not-inc</th>\n",
       "      <th>Workclass_ State-gov</th>\n",
       "      <th>Workclass_ Without-pay</th>\n",
       "      <th>Education_ 10th</th>\n",
       "      <th>Education_ 11th</th>\n",
       "      <th>Education_ 12th</th>\n",
       "      <th>Education_ 1st-4th</th>\n",
       "      <th>Education_ 5th-6th</th>\n",
       "      <th>Education_ 7th-8th</th>\n",
       "      <th>Education_ 9th</th>\n",
       "      <th>Education_ Assoc-acdm</th>\n",
       "      <th>Education_ Assoc-voc</th>\n",
       "      <th>Education_ Bachelors</th>\n",
       "      <th>Education_ Doctorate</th>\n",
       "      <th>Education_ HS-grad</th>\n",
       "      <th>Education_ Masters</th>\n",
       "      <th>Education_ Preschool</th>\n",
       "      <th>Education_ Prof-school</th>\n",
       "      <th>Education_ Some-college</th>\n",
       "      <th>Race_ Amer-Indian-Eskimo</th>\n",
       "      <th>Race_ Asian-Pac-Islander</th>\n",
       "      <th>Race_ Black</th>\n",
       "      <th>Race_ Other</th>\n",
       "      <th>Race_ White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16054</td>\n",
       "      <td>42</td>\n",
       "      <td>29297</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32382</td>\n",
       "      <td>44</td>\n",
       "      <td>19099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10749</td>\n",
       "      <td>39</td>\n",
       "      <td>-5147</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15377</td>\n",
       "      <td>39</td>\n",
       "      <td>16476</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29660</td>\n",
       "      <td>29</td>\n",
       "      <td>-24893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1408</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  fnlwgt  Sex  Capital_Gain  Capital_Loss  Hours_per_week  \\\n",
       "16054   42   29297    2             0             0              40   \n",
       "32382   44   19099    1             0             0              40   \n",
       "10749   39   -5147    2             0             0              40   \n",
       "15377   39   16476    2             0             0              40   \n",
       "29660   29  -24893    1             0          1408              40   \n",
       "\n",
       "       Workclass_ ?  Workclass_ Federal-gov  Workclass_ Local-gov  \\\n",
       "16054             0                       0                     0   \n",
       "32382             0                       0                     1   \n",
       "10749             0                       0                     1   \n",
       "15377             0                       0                     0   \n",
       "29660             0                       1                     0   \n",
       "\n",
       "       Workclass_ Never-worked  Workclass_ Private  Workclass_ Self-emp-inc  \\\n",
       "16054                        0                   0                        0   \n",
       "32382                        0                   0                        0   \n",
       "10749                        0                   0                        0   \n",
       "15377                        0                   1                        0   \n",
       "29660                        0                   0                        0   \n",
       "\n",
       "       Workclass_ Self-emp-not-inc  Workclass_ State-gov  \\\n",
       "16054                            0                     1   \n",
       "32382                            0                     0   \n",
       "10749                            0                     0   \n",
       "15377                            0                     0   \n",
       "29660                            0                     0   \n",
       "\n",
       "       Workclass_ Without-pay  Education_ 10th  Education_ 11th  \\\n",
       "16054                       0                0                0   \n",
       "32382                       0                0                0   \n",
       "10749                       0                0                0   \n",
       "15377                       0                0                0   \n",
       "29660                       0                0                0   \n",
       "\n",
       "       Education_ 12th  Education_ 1st-4th  Education_ 5th-6th  \\\n",
       "16054                0                   0                   0   \n",
       "32382                0                   0                   0   \n",
       "10749                0                   0                   0   \n",
       "15377                0                   0                   0   \n",
       "29660                0                   0                   0   \n",
       "\n",
       "       Education_ 7th-8th  Education_ 9th  Education_ Assoc-acdm  \\\n",
       "16054                   0               0                      0   \n",
       "32382                   0               0                      0   \n",
       "10749                   0               0                      0   \n",
       "15377                   0               0                      0   \n",
       "29660                   0               0                      0   \n",
       "\n",
       "       Education_ Assoc-voc  Education_ Bachelors  Education_ Doctorate  \\\n",
       "16054                     0                     0                     0   \n",
       "32382                     0                     0                     0   \n",
       "10749                     0                     1                     0   \n",
       "15377                     0                     0                     0   \n",
       "29660                     0                     0                     0   \n",
       "\n",
       "       Education_ HS-grad  Education_ Masters  Education_ Preschool  \\\n",
       "16054                   1                   0                     0   \n",
       "32382                   1                   0                     0   \n",
       "10749                   0                   0                     0   \n",
       "15377                   1                   0                     0   \n",
       "29660                   0                   0                     0   \n",
       "\n",
       "       Education_ Prof-school  Education_ Some-college  \\\n",
       "16054                       0                        0   \n",
       "32382                       0                        0   \n",
       "10749                       0                        0   \n",
       "15377                       0                        0   \n",
       "29660                       0                        1   \n",
       "\n",
       "       Race_ Amer-Indian-Eskimo  Race_ Asian-Pac-Islander  Race_ Black  \\\n",
       "16054                         0                         0            0   \n",
       "32382                         0                         0            0   \n",
       "10749                         0                         0            0   \n",
       "15377                         0                         0            0   \n",
       "29660                         0                         0            0   \n",
       "\n",
       "       Race_ Other  Race_ White  \n",
       "16054            0            1  \n",
       "32382            0            1  \n",
       "10749            0            1  \n",
       "15377            0            1  \n",
       "29660            0            1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To connect the What-if Tool to an AI Platform model, you need to pass it a subset of your test examples.  The commannd below will create a Numpy array of 2000 from our test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the features and labels into one array for the What-if Tool\n",
    "\n",
    "num_wit_examples = 2000\n",
    "\n",
    "test_examples = np.hstack((\n",
    "    x_test[:num_wit_examples],\n",
    "    y_test[:num_wit_examples].reshape(-1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Instantiating the What-if Tool is as simple as creating a WitConfigBuilder object and passing it the AI Platform model desired to be analyzed.\n",
    "\n",
    "The optional \"adjust_prediction\" parameter is used because the What-if Tool expects a list of scores for each class in our model (in this case 2). Since the model only returns a single value from 0 to 1, it must be transformed to the correct format in this function.   Lastly, the name 'income_prediction' is used as the ground truth label.\n",
    "\n",
    "It may take 1 to 2 minutes for the What-if Tool to load and render the visualization palette, please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dherin-sandbox'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost_model'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8797f1c437ce4d5087334a59f0458f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': ['low', 'high'], 'feature_names': ['Age', 'fnâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FEATURE_NAMES = features.columns.tolist() + ['income_prediction']\n",
    "\n",
    "\n",
    "def adjust(pred):\n",
    "    return [1 - pred, pred]\n",
    "\n",
    "\n",
    "config_builder = (\n",
    "    WitConfigBuilder(test_examples.tolist(), FEATURE_NAMES)\n",
    "    .set_ai_platform_model(PROJECT, MODEL, VERSION, adjust_prediction=adjust)\n",
    "    .set_target_feature('income_prediction')\n",
    "    .set_label_vocab(['low', 'high'])\n",
    ")\n",
    "\n",
    "WitWidget(config_builder, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## In the following steps we will use the What-if Tool to examine our model \n",
    "\n",
    "Since the What-If Tool is embedded in the notebook you must use care when scrolling.  The What-if Tool has its own internal scrolling windows so you may need to reposition the frame window to reach the desired location.  To do this you must ensure you are at the far edges of the cell to scroll up and down as noted by the red oblong markers in the image below.\n",
    "\n",
    "Also, it might be helpful to widen the display frame in the notebook.  You can do this by dragging the vertical grey bar to the left (the place to click and hold is noted by the red arrows).\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/WIT_25.png \"WIT UI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The scenario for consideration is that this model, which is used to predict income levels, will be used in a loan approval process.   Your task is to determine its fitness for such a use case from a fairness perspective.\n",
    "\n",
    "Your first action will be to examine data and its disribution along dimensions that are relevant to loan scoring.   The intial presentation in the tool shows all datapoints.  Blue dots are those individuals predicted as having incomes above 50k.  Red dots are those predicted as having incomes below 50k.\n",
    "\n",
    "On the \"Datapoint Editor\" tab, under \"Binning | X-Axis\" select \"Education_Masters\":\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/BinX_Menu_Choice.png \"BinX Menu\")\n",
    "\n",
    "The results show that a majority of Masters degree holders, domain value \"1\" (in red above the visualization), have incomes above 50k.\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/BinX_Results.png \"BinX Results\")\n",
    "\n",
    "Return to the \"Binning | X-Axis\" selector and choose \"None\" to reset the visualization.\n",
    "\n",
    "---\n",
    "\n",
    "Next navigate to the Features tab, here you can see the exact distribution of values for every feature in the dataset.  If you type \"sex\" into the filter box, you will see that of the 2,000 test datapoints, 670 from Women and 1,330 are from Men (as mentioned earlier the value \"1\" was assigned to Females and \"2\" was assigned to Males). The dataset reflects an imbalance between Females and Males with nearly double the number of cases that are Male. Women seem under-represented in this dataset.\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/Features.png \"Features\")\n",
    "\n",
    "On the \"Performance + Fairness\" tab, you can set an input feature (or set of features) by which to slice the data. This will allow you to evaluate the fairness of specific groups.  Income Prediction (corresponding to over or under 50k) has already been selected as the \"Ground Truth Feature\". On the \"Slice by\" selector, scroll to find and choose \"Sex\".\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/PerfTab.png \"PerfTab\")\n",
    "\n",
    "This selection allows you to see the breakdown of model performance on female datapoints versus male datapoints.  Even before you drill into the details you can see that the model has a higher false accuracy value for females than males. Drilling down on each value (by clicking the arrow beside the domain value) you see that the model predicts high income for females much less than it does for males:  3.4% of the time for females vs 18.9% of the time for males.\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/MaleDetails.png \"Male Details\")\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/FemaleDetails.png \"Female Details\")\n",
    "\n",
    "In the use-case scenario, the plan is to use this simple income classifier to approve or reject loan applications (not a realistic example but it illustrates the effect of bias in ML usage). In this case, 18.9% of men from the test dataset have their loans approved but only 3.4% of women have their loans approved. If you wanted to ensure than men and women get their loans approved the same percentage of the time, that is a fairness concept called \"demographic parity\". An XGBoost model intially defaults to a 0.50 threshold, which is what appears upon initial examination.  One way to achieve demographic parity would be to have different classification thresholds for females and males in our model. You'll notice there is a button on the tool labeled \"demographic parity\". When you press this button, the tool will take the cost ratio into account, and come up with ideal separate thresholds for men and women that will achieve demographic parity over the test dataset.\n",
    "\n",
    "On the \"Performance + Fairness\" tab, select \"Demographic Parity\" to see the results.\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/DemoParityButton_Resize.png \"Demographic Parity Button\")\n",
    "\n",
    "By drilling down on each domain value you can see the automatic adjustments.  In this case, demographic parity can be found with both groups getting loans approved/predicting a high income ~17.7% of the time.  This occurs when the female threshold is set to 0.19 and the male threshold is set to 0.54. Because of the vast difference in the properties of the female and male training data in this 1994 census dataset, you need quite different thresholds to achieve demographic parity. With the high male threshold you may notice there are many more false negatives than before, and with the low female threshold there are many more false positives than before.  To reset the Peformance and Fairness Tab simply choose another domain value in the \"Slice by\" selector.\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/MaleDemoParitySlider.png \"Male Demo Parity\")\n",
    "\n",
    "![alt_text](https://storage.cloud.google.com/cloud-training-demos/mlfairness/images/FemaleDemoParitySlider.png \"Female Demo Parity\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The use of these features can help shed light on subsets of your data on which your classifier is performing very differently. Understanding biases in your datasets and data slices on which your model has disparate performance are very important parts of analyzing a model for fairness. There are many approaches to improving fairness, including augmenting training data, building fairness-related loss functions into your model training procedure, and post-training inference adjustments like those seen in WIT. The WIT provides a great interface for furthering ML fairness learning, but of course there is no silver bullet to improving ML fairness.\n",
    "\n",
    "Feel free to explore the What-if Tool and find additional insights.\n",
    "\n",
    "This is the end of the lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
