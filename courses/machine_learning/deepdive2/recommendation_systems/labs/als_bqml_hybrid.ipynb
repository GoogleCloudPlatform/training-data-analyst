{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Recommendations with the Movie Lens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ It is recommended that you complete the companion __als_bqml.ipynb__ notebook before continuing with this __als_bqml_hybrid.ipynb__ notebook. This is, however, not a requirement for this lab as you have the option to bring over the dataset + trained model. If you already have the movielens dataset and trained model you can skip the \"Import the dataset and trained model\" section.\n",
    "\n",
    "## Learning Objectives\n",
    "1. Know extract user and product factors from a BigQuery Matrix Factorizarion Model\n",
    "2. Know how to format inputs for a BigQuery Hybrid Recommendation Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "PROJECT = \"your-project-id-here\" # REPLACE WITH YOUR PROJECT ID\n",
    "\n",
    "# Do not change these\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"TFVERSION\"] = '2.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset and trained model\n",
    "In the previous notebook, you imported 20 million movie recommendations and trained an ALS model with BigQuery ML\n",
    "\n",
    "To save you the steps of having to do so again (if this is a new environment) you can run the below commands to copy over the clean data and trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the BigQuery dataset and copy over the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq mk movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE movielens.ratings AS\n",
    "SELECT * FROM `cloud-training-demos`.movielens.ratings;\n",
    "\n",
    "CREATE OR REPLACE TABLE movielens.movies AS \n",
    "SELECT * FROM `cloud-training-demos`.movielens.movies;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, copy over the trained recommendation model. Note that if you're project is in the EU you will need to change the location from US to EU below. Note that as of the time of writing you cannot copy models across regions with `bq cp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bq --location=US cp \\\n",
    "cloud-training-demos:movielens.recommender_16 \\\n",
    "movielens.recommender_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, ensure the model still works by invoking predictions for movie recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "SELECT * FROM\n",
    "ML.PREDICT(MODEL `movielens.recommender_16`, (\n",
    "  SELECT \n",
    "    movieId, title, 903 AS userId\n",
    "  FROM movielens.movies, UNNEST(genres) g\n",
    "  WHERE g = 'Comedy'\n",
    "))\n",
    "ORDER BY predicted_rating DESC\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating user and movie information \n",
    "The matrix factorization approach does not use any information about users or movies beyond what is available from the ratings matrix. However, we will often have user information (such as the city they live, their annual income, their annual expenditure, etc.) and we will almost always have more information about the products in our catalog. How do we incorporate this information in our recommendation model?\n",
    "\n",
    "The answer lies in recognizing that the user factors and product factors that result from the matrix factorization approach end up being a concise representation of the information about users and products available from the ratings matrix. We can concatenate this information with other information we have available and train a regression model to predict the rating.\n",
    "### Obtaining user and product factors\n",
    "We can get the user factors or product factors from ML.WEIGHTS. For example to get the product factors for movieId=96481 and user factors for userId=54192, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "SELECT \n",
    "    processed_input,\n",
    "    feature,\n",
    "    TO_JSON_STRING(factor_weights),\n",
    "    intercept\n",
    "FROM ML.WEIGHTS(MODEL movielens.recommender_16)\n",
    "WHERE\n",
    "    (processed_input = 'movieId' AND feature = '96481')\n",
    "    OR (processed_input = 'userId' AND feature = '54192')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying these weights and adding the intercept is how we get the predicted rating for this combination of movieId and userId in the matrix factorization approach.\n",
    "\n",
    "These weights also serve as a low-dimensional representation of the movie and user behavior. We can create a regression model to predict the rating given the user factors, product factors, and any other information we know about our users and products.\n",
    "### Creating input features\n",
    "The MovieLens dataset does not have any user information, and has very little information about the movies themselves. To illustrate the concept, therefore, let’s create some synthetic information about users:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "CREATE OR REPLACE TABLE movielens.users AS\n",
    "SELECT\n",
    "    userId,\n",
    "    RAND() * COUNT(rating) AS loyalty,\n",
    "    CONCAT(SUBSTR(CAST(userId AS STRING), 0, 2)) AS postcode\n",
    "FROM\n",
    "  movielens.ratings\n",
    "GROUP BY userId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input features about users can be obtained by joining the user table with the ML weights and selecting all the user information and the user factors from the weights array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "WITH userFeatures AS (\n",
    "  SELECT \n",
    "     u.*,\n",
    "     (SELECT ARRAY_AGG(weight) FROM UNNEST(factor_weights)) AS user_factors\n",
    "  FROM movielens.users u\n",
    "  JOIN ML.WEIGHTS(MODEL movielens.recommender_16) w\n",
    "  ON processed_input = 'userId' AND feature = CAST(u.userId AS STRING)\n",
    ")\n",
    "\n",
    "SELECT * FROM userFeatures\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can get product features for the movies data, except that we have to decide how to handle the genre since a movie could have more than one genre. If we decide to create a separate training row for each genre, then we can construct the product features using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "WITH productFeatures AS (\n",
    "  SELECT \n",
    "      p.* EXCEPT(genres),\n",
    "      g, (SELECT ARRAY_AGG(weight) FROM UNNEST(factor_weights))\n",
    "            AS product_factors\n",
    "  FROM movielens.movies p, UNNEST(genres) g\n",
    "  JOIN ML.WEIGHTS(MODEL movielens.recommender_16) w\n",
    "  ON processed_input = 'movieId' AND feature = CAST(p.movieId AS STRING)\n",
    ")\n",
    "\n",
    "SELECT * FROM productFeatures\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining these two WITH clauses and pulling in the rating corresponding the movieId-userId combination (if it exists in the ratings table), we can create the training dataset.\n",
    "\n",
    "**TODO 1**: Combine the above two queries to get the user factors and product factor for each rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "CREATE OR REPLACE TABLE movielens.hybrid_dataset AS\n",
    "\n",
    "    WITH userFeatures AS (\n",
    "      # TODO: Place the user features query here\n",
    "    ),\n",
    "\n",
    "    productFeatures AS (\n",
    "      # TODO: Place the product features query here\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "        p.* EXCEPT(movieId),\n",
    "        u.* EXCEPT(userId),\n",
    "        rating \n",
    "    FROM productFeatures p, userFeatures u\n",
    "    JOIN movielens.ratings r\n",
    "    ON r.movieId = p.movieId AND r.userId = u.userId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the rows of this table looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "SELECT *\n",
    "FROM movielens.hybrid_dataset\n",
    "LIMIT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, we have a couple of attributes about the movie, the product factors array corresponding to the movie, a couple of attributes about the user, and the user factors array corresponding to the user. These form the inputs to our “hybrid” recommendations model that builds off the matrix factorization model and adds in metadata about users and movies.\n",
    "### Training hybrid recommendation model\n",
    "At the time of writing, BigQuery ML can not handle arrays as inputs to a regression model. Let’s, therefore, define a function to convert arrays to a struct where the array elements are its fields:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "CREATE OR REPLACE FUNCTION movielens.arr_to_input_16_users(u ARRAY<FLOAT64>)\n",
    "RETURNS \n",
    "    STRUCT<\n",
    "        u1 FLOAT64,\n",
    "        u2 FLOAT64,\n",
    "        u3 FLOAT64,\n",
    "        u4 FLOAT64,\n",
    "        u5 FLOAT64,\n",
    "        u6 FLOAT64,\n",
    "        u7 FLOAT64,\n",
    "        u8 FLOAT64,\n",
    "        u9 FLOAT64,\n",
    "        u10 FLOAT64,\n",
    "        u11 FLOAT64,\n",
    "        u12 FLOAT64,\n",
    "        u13 FLOAT64,\n",
    "        u14 FLOAT64,\n",
    "        u15 FLOAT64,\n",
    "        u16 FLOAT64\n",
    "    > AS (STRUCT(\n",
    "        u[OFFSET(0)],\n",
    "        u[OFFSET(1)],\n",
    "        u[OFFSET(2)],\n",
    "        u[OFFSET(3)],\n",
    "        u[OFFSET(4)],\n",
    "        u[OFFSET(5)],\n",
    "        u[OFFSET(6)],\n",
    "        u[OFFSET(7)],\n",
    "        u[OFFSET(8)],\n",
    "        u[OFFSET(9)],\n",
    "        u[OFFSET(10)],\n",
    "        u[OFFSET(11)],\n",
    "        u[OFFSET(12)],\n",
    "        u[OFFSET(13)],\n",
    "        u[OFFSET(14)],\n",
    "        u[OFFSET(15)]\n",
    "));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "SELECT movielens.arr_to_input_16_users(u).*\n",
    "FROM (SELECT\n",
    "    [0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15.] AS u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a similar function named movielens.arr_to_input_16_products to convert the product factor array into named columns.\n",
    "\n",
    "**TODO 2**: Create a function that returns named columns from a size 16 product factor array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "CREATE OR REPLACE FUNCTION movielens.arr_to_input_16_products(p ARRAY<FLOAT64>)\n",
    "RETURNS \n",
    "    STRUCT<\n",
    "        p1 FLOAT64,\n",
    "        p2 FLOAT64,\n",
    "        p3 FLOAT64,\n",
    "        p4 FLOAT64,\n",
    "        p5 FLOAT64,\n",
    "        p6 FLOAT64,\n",
    "        p7 FLOAT64,\n",
    "        p8 FLOAT64,\n",
    "        p9 FLOAT64,\n",
    "        p10 FLOAT64,\n",
    "        p11 FLOAT64,\n",
    "        p12 FLOAT64,\n",
    "        # TODO: Finish building this struct\n",
    "    > AS (STRUCT(\n",
    "        p[OFFSET(0)],\n",
    "        p[OFFSET(1)],\n",
    "        p[OFFSET(2)],\n",
    "        p[OFFSET(3)],\n",
    "        p[OFFSET(4)],\n",
    "        p[OFFSET(5)],\n",
    "        p[OFFSET(6)],\n",
    "        p[OFFSET(7)],\n",
    "        p[OFFSET(8)],\n",
    "        p[OFFSET(9)],\n",
    "        p[OFFSET(10)],\n",
    "        p[OFFSET(11)],\n",
    "        p[OFFSET(12)],\n",
    "        # TODO: Finish building this struct\n",
    "));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can tie together metadata about users and products with the user factors and product factors obtained from the matrix factorization approach to create a regression model to predict the rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "CREATE OR REPLACE MODEL movielens.recommender_hybrid \n",
    "OPTIONS(model_type='linear_reg', input_label_cols=['rating'])\n",
    "AS\n",
    "\n",
    "SELECT\n",
    "  * EXCEPT(user_factors, product_factors),\n",
    "    movielens.arr_to_input_16_users(user_factors).*,\n",
    "    movielens.arr_to_input_16_products(product_factors).*\n",
    "FROM\n",
    "  movielens.hybrid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no point looking at the evaluation metrics of this model because the user information we used to create the training dataset was fake (not the RAND() in the creation of the loyalty column) -- we did this exercise in order to demonstrate how it could be done. And of course, we could train a dnn_regressor model and optimize the hyperparameters if we want a more sophisticated model. But if we are going to go that far, it might be better to consider using Auto ML tables, covered in the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
