{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MNIST Image Classification with TensorFlow\n",
    "\n",
    "This notebook demonstrates how to implement a simple linear image models on MNIST using Estimator.\n",
    "<hr/>\n",
    "This <a href=\"mnist_models.ipynb\">companion notebook</a> extends the basic harness of this notebook to a variety of models including DNN, CNN, dropout, pooling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "NCLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO=12\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Using low-level tensorflow\n",
    "def linear_model(img):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  W = tf.get_variable(\"W\", [HEIGHT*WIDTH,NCLASSES], \n",
    "                      initializer = tf.truncated_normal_initializer(stddev=0.1,seed = 1))\n",
    "  b = tf.get_variable(\"b\",NCLASSES, initializer = tf.zeros_initializer)\n",
    "  ylogits = tf.matmul(X,W)+b\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we can also build our linear classifer using the tf.layers API. Notice when using tf.layers we don't have to define or initialize our weights and biases. This happens automatically for us in the background.\n",
    "\n",
    "When building more complex models such as DNNs and CNNs our code will be much more readable by using the tf.layers API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using tf.layers API\n",
    "def linear_model(img):\n",
    "  X = tf.reshape(img,[-1,HEIGHT*WIDTH]) #flatten\n",
    "  ylogits = tf.layers.dense(X,NCLASSES,activation=None)\n",
    "  return ylogits, NCLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write Input Functions\n",
    "\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.train.images},\n",
    "    y=mnist.train.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'image':mnist.test.images},\n",
    "    y=mnist.test.labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=1,\n",
    "    shuffle=False,\n",
    "    queue_capacity=5000\n",
    "  )\n",
    "\n",
    "def serving_input_fn():\n",
    "    inputs = {'image': tf.placeholder(tf.float32, [None, HEIGHT, WIDTH])}\n",
    "    features = inputs # as-is\n",
    "    return tf.estimator.export.ServingInputReceiver(features, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write Custom Estimator\n",
    "I could have simply used a canned LinearClassifier, but later on, I will want to use different models, and so let's write a custom estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def image_classifier(features, labels, mode, params):\n",
    "  ylogits, nclasses = linear_model(features['image'])\n",
    "  probabilities = tf.nn.softmax(ylogits)\n",
    "  classes = tf.cast(tf.argmax(probabilities, 1), tf.uint8)\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ylogits, labels=labels))\n",
    "    evalmetrics =  {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, 1))}\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      train_op = tf.contrib.layers.optimize_loss(loss, tf.train.get_global_step(),\n",
    "                                                 learning_rate=params['learning_rate'], optimizer=\"Adam\")\n",
    "    else:\n",
    "      train_op = None\n",
    "  else:\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    evalmetrics = None\n",
    " \n",
    "  return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\"probabilities\": probabilities, \"classes\": classes},\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=evalmetrics,\n",
    "        export_outputs={'classes': tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"classes\": classes})}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " tf.estimator.train_and_evaluate does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "  estimator = tf.estimator.Estimator(model_fn = image_classifier,\n",
    "                                     params = hparams,\n",
    "                                     model_dir = output_dir)\n",
    "  train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                    max_steps = hparams['train_steps'])\n",
    "  exporter = tf.estimator.LatestExporter('Servo', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
    "                                  steps = None,\n",
    "                                  exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "OUTDIR='mnist/learned'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {'train_steps': 1000, 'learning_rate': 0.01}\n",
    "train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got:\n",
    "\n",
    "`Saving dict for global step 1000: accuracy = 0.9158, global_step = 1000, loss = 0.29720208`\n",
    "\n",
    "In other words, we achieved 91.6% accuracy with the simple linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
