{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter tuning with Cloud ML Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Learning Objectives:**\n",
    "  * Improve the accuracy of a model by hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'cloud-training-demos' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'cloud-training-demos-ml' # REPLACE WIHT YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "os.environ['TFVERSION'] = '1.4'  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Create command-line program\n",
    "\n",
    "In order to submit to Cloud ML Engine, we need to create a distributed training program. Let's convert our housing example to fit that paradigm, using the Estimators API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf trainer\n",
    "mkdir trainer\n",
    "touch trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile trainer/house.py\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def train(output_dir, batch_size, learning_rate):\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  \n",
    "  # Read dataset and split into train and eval\n",
    "  df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")\n",
    "  df['num_rooms'] = df['total_rooms'] / df['households']\n",
    "  msk = np.random.rand(len(df)) < 0.8\n",
    "  traindf = df[msk]\n",
    "  evaldf = df[~msk]\n",
    "\n",
    "  # Train and eval input functions\n",
    "  SCALE = 100000\n",
    "  \n",
    "  train_input_fn = tf.estimator.inputs.pandas_input_fn(x = traindf[[\"num_rooms\"]],\n",
    "                                                       y = traindf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                                       num_epochs = 1,\n",
    "                                                       batch_size = batch_size, # note the batch size\n",
    "                                                       shuffle = True)\n",
    "  \n",
    "  eval_input_fn = tf.estimator.inputs.pandas_input_fn(x = evaldf[[\"num_rooms\"]],\n",
    "                                                      y = evaldf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                                      num_epochs = 1,\n",
    "                                                      batch_size = len(evaldf),\n",
    "                                                      shuffle=False)\n",
    "  \n",
    "  # Define feature columns\n",
    "  features = [tf.feature_column.numeric_column('num_rooms')]\n",
    "  \n",
    "  def train_and_evaluate(output_dir):\n",
    "    # Compute appropriate number of steps\n",
    "    num_steps = (len(traindf) / batch_size) / learning_rate  # if learning_rate=0.01, hundred epochs\n",
    "\n",
    "    # Create custom optimizer\n",
    "    myopt = tf.train.FtrlOptimizer(learning_rate = learning_rate) # note the learning rate\n",
    "\n",
    "    # Create rest of the estimator as usual\n",
    "    estimator = tf.estimator.LinearRegressor(model_dir = output_dir, \n",
    "                                             feature_columns = features, \n",
    "                                             optimizer = myopt)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = train_input_fn,\n",
    "                                        max_steps = num_steps)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = eval_input_fn,\n",
    "                                      steps = None)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "  # Run the training\n",
    "  shutil.rmtree(output_dir, ignore_errors=True) # start fresh each time\n",
    "  train_and_evaluate(output_dir)\n",
    "    \n",
    "if __name__ == '__main__' and \"get_ipython\" not in dir():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      type = float, \n",
    "      default = 0.01\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--batch_size',\n",
    "      type = int, \n",
    "      default = 30\n",
    "  ),\n",
    "  parser.add_argument(\n",
    "      '--job-dir',\n",
    "      help = 'GCS location to write checkpoints and export models.',\n",
    "      required = True\n",
    "  )\n",
    "  args = parser.parse_args()\n",
    "  print(\"Writing checkpoints to {}\".format(args.job_dir))\n",
    "  train(args.job_dir, args.batch_size, args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf house_trained\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.house \\\n",
    "    --job-dir=house_trained \\\n",
    "    --package-path=$(pwd)/trainer \\\n",
    "    -- \\\n",
    "    --batch_size=30 \\\n",
    "    --learning_rate=0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create hyperparam.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 5\n",
    "    maxParallelTrials: 1\n",
    "    hyperparameterMetricTag: average_loss\n",
    "    params:\n",
    "    - parameterName: batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 64\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/house_trained   # CHANGE bucket name appropriately\n",
    "gsutil rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training house_$(date -u +%y%m%d_%H%M%S) \\\n",
    "   --config=hyperparam.yaml \\\n",
    "   --module-name=trainer.house \\\n",
    "   --package-path=$(pwd)/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --runtime-version=$TFVERSION \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine jobs describe house_180403_231031 # CHANGE jobId appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge exercise\n",
    "Add a few engineered features to the housing model, and use hyperparameter tuning to choose which set of features the model uses.\n",
    "\n",
    "<p>\n",
    "Copyright 2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
